{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f07b1c9-6f45-4bcd-87b5-a70ed6ad20fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Building Demand Method 1 Simplified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b918d9f-e01d-4238-b360-cb31623a416d",
   "metadata": {},
   "source": [
    "#### Brief overview:\n",
    "\n",
    "The energy demand for each cell is assessed according to the following parameters:\n",
    "𝐵 Number of buildings\n",
    "𝑆𝑟𝑒𝑠 Share of res buildings\n",
    "𝑁 Nb of HH per res buildings\n",
    "𝑎 Electrified status (probability)\n",
    "𝐸_𝐻𝐻  Energy consumption per HH\n",
    "𝑟 Adjustment with RWI\n",
    "\n",
    "For each cell c, we have 𝐷_𝑐=𝐵_𝑐∗𝑆𝑟𝑒𝑠∗𝑁_𝑐  ∗𝑎_𝑐  ∗𝐸_𝐻𝐻  ∗𝑟_𝑐 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab8d2f-f9de-4c1c-be79-52401bbd1519",
   "metadata": {},
   "source": [
    "### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5444dd77-265a-4e88-a814-100c3710d66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move to C:\\Users\\amillot\\PycharmProjects\\DemandMappingZambia\n"
     ]
    }
   ],
   "source": [
    "# Check if we are running the notebook directly, if so move workspace to parent dir\n",
    "import sys\n",
    "import os\n",
    "currentdir = os.path.abspath(os.getcwd())\n",
    "if os.path.basename(currentdir) != 'DemandMappingZambia':  \n",
    "  sys.path.insert(0, os.path.dirname(currentdir))\n",
    "  os.chdir('..')\n",
    "  print(f'Move to {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a61b0c1d-0c29-48e5-9101-2d4b3aa385cf",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Activate geospatial_env first\n",
    "\n",
    "# Numeric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# System\n",
    "import shutil\n",
    "from IPython.display import display, Markdown, HTML, FileLink, FileLinks\n",
    "\n",
    "# Spatial\n",
    "import geopandas as gpd\n",
    "# import json\n",
    "# import pyproj\n",
    "# from shapely.geometry import Point, Polygon, MultiPoint\n",
    "# from shapely.geometry.polygon import Polygon\n",
    "# from shapely.geometry import shape, mapping\n",
    "# from shapely.wkt import dumps, loads\n",
    "# from shapely.ops import nearest_points\n",
    "# from shapely.ops import unary_union\n",
    "from pyproj import CRS\n",
    "# from osgeo import ogr, gdal, osr\n",
    "# from rasterstats import zonal_stats\n",
    "# import rasterio\n",
    "# from geojson import Feature, Point, FeatureCollection\n",
    "# import rasterio.fill\n",
    "# import json\n",
    "# import fiona\n",
    "# import h3 as h3\n",
    "\n",
    "# Mapping / Plotting\n",
    "# from functools import reduce\n",
    "# import folium\n",
    "# from folium.features import GeoJsonTooltip\n",
    "# from folium.plugins import BeautifyIcon\n",
    "# from folium.plugins import HeatMap\n",
    "# import branca.colormap as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import matplotlib.colors as colors\n",
    "# %matplotlib inline\n",
    "\n",
    "import importlib\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff55a57-e9f1-4597-9e92-b5f0087b40c2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import datetime\n",
    "# import warnings\n",
    "# import scipy.spatial\n",
    "from scipy.optimize import fsolve\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.attributes(\"-topmost\", True)\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c47c87c-8664-4ea1-a1a3-5e5b33c465f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from 'C:\\\\Users\\\\amillot\\\\PycharmProjects\\\\DemandMappingZambia\\\\config.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import config\n",
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52ae53ed-deb3-49ce-9d03-200d1017c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import processing_raster, finalizing_rasters, convert_features_to_geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42030ea-5877-4a38-b64a-544fc8c2e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Residential.data_loader import load_initial_data, extract_raster_data, load_un_stats, load_census_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9791cdf6-37cf-4422-b34b-d305f5c6c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = config.AREA_OF_INTEREST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfdae20-245c-4079-b948-9e4ccb0f208f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d438a-e9da-4b81-8b1f-4b9b0bbf8a8e",
   "metadata": {},
   "source": [
    "### Load initial data grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b310d8-61f5-4806-bc0e-07c135137f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading initial data...\n",
      "Admin boundaries loaded. Country GDF: (1, 3), Region GDF: (10, 12)\n",
      "Hexagon grid loaded: (17552, 11)\n",
      "EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "# Load initial data (grid and administrative boundaries)\n",
    "regions, admin_gdf, region_gdf, grid = load_initial_data(config)\n",
    "print(grid.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c628b49-d0f7-4b64-a623-91b775fd2782",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Extract raster values to hexagons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4fc3e1-b706-4f41-bf0a-4f65a8b138c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting raster data...\n",
      "EPSG:4326\n",
      "2025-06-14 18:12:37.497884\n",
      "Processed WorldPop Buildings Count.\n",
      "2025-06-14 18:18:10.716003\n",
      "Processed WorldPop Urban.\n"
     ]
    }
   ],
   "source": [
    "# Extract raster data\n",
    "grid = extract_raster_data(grid, config, processing_raster, convert_features_to_geodataframe)\n",
    "print(grid.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c68d7-353f-4535-bfe7-123890e9f092",
   "metadata": {},
   "source": [
    "### Extract residential and service demand from UN stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ab8a6-5235-4456-98d7-d5438c7a5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_residential_elec_GWh, total_services_elec_GWh = load_un_stats(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121fe47-06d3-47ae-bf96-ae1f0afa5ef8",
   "metadata": {},
   "source": [
    "### Load Census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26343e7-cdf9-48a1-bb93-3a5e29cd7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_HH, df_censusdata = load_census_data(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570589bc-ef10-4b9a-8708-8b790f85aae0",
   "metadata": {},
   "source": [
    "## Residential electricity consumption assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb3f44-0e71-4651-977c-d0a370e8bb37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Step 1: assess the number of HH with access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7a795-cd15-419e-b534-ff9e712093f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the buildings map\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "grid.sort_values('buildingssum', ascending=True).plot(\n",
    "    ax=ax, column='buildingssum', cmap=\"Reds\", legend=True, alpha=0.9)\n",
    "ax.set_aspect('equal', 'box')\n",
    "# txt = ax.set_title('Buildings in {}'.format(area) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a728537-2c06-4590-bce9-e5e50fbb2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid['buildingssum'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17d01e-fb87-460f-895f-34eb51e1263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the lighting map\n",
    "# Create the axis first\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Filter the data\n",
    "grid_filtered = grid[(grid['buildingssum'] >= 1000) & (grid['HREA'] <= 0.1)]\n",
    "grid_filtered = grid[(grid['buildingssum'] >= 2)]\n",
    "# Plot data\n",
    "grid_filtered.sort_values('HREA', ascending=True).plot(\n",
    "    ax=ax, column='HREA', cmap=\"Reds\", legend=True, alpha=0.9)\n",
    "# # Plot data\n",
    "# grid.sort_values('buildingssum', ascending=True).plot(\n",
    "#     ax=ax, column='buildingssum', cmap=\"Blues\", legend=True, alpha=0.9)\n",
    "\n",
    "ax.set_aspect('equal', 'box')\n",
    "# txt = ax.set_title('HREA in {}'.format(area) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91245c5b-c6ce-4a7e-a41c-6e215dc7b65e",
   "metadata": {},
   "source": [
    "#### Determine location (ruban or rural) of each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf6875-0c04-49fd-a73e-3744b992dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_location_status(grid_gdf, app_config):\n",
    "    \"\"\"\n",
    "    Determines urban/rural status for each grid cell based on WorldPop urban extent data.\n",
    "\n",
    "    Args:\n",
    "        grid_gdf: GeoDataFrame of the hexagonal grid with WorldPop data.\n",
    "        app_config: The configuration module.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: grid_gdf with an added column for location status.\n",
    "    \"\"\"\n",
    "    print(\"Determining location status (urban/rural)...\")\n",
    "    if app_config.COL_LOCATION_WP not in grid_gdf.columns:\n",
    "        raise KeyError(f\"Required column '{app_config.COL_LOCATION_WP}' not found in grid. Available: {grid_gdf.columns.tolist()}\")\n",
    "\n",
    "    grid_gdf[app_config.COL_LOC_ASSESSED] = grid_gdf.apply(\n",
    "        lambda row: \"urban\" if row[app_config.COL_LOCATION_WP] == 1 else \"rural\",\n",
    "        axis=1\n",
    "    )\n",
    "    # Other methods\n",
    "    # grid[\"locGHSL\"] = grid.apply (lambda row: (\"urban\" if ((row['SMOD'] == 30) or (row['SMOD'] == 21) or (row['SMOD'] == 22) or (row['SMOD' ] == 23)) \n",
    "#                                              else \"rural\"), axis=1)\n",
    "    # grid[\"locAssessed\"] = grid.apply(lambda row: (\"urban\" if ((row['buildingssum'] > 1000)) # number chosen to get 1 for nb of HH per rural building\n",
    "#                                              else \"rural\"), axis=1)\n",
    "    print(f\"'{app_config.COL_LOC_ASSESSED}' column created. Counts: {grid_gdf[app_config.COL_LOC_ASSESSED].value_counts().to_dict()}\")\n",
    "    return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde9b50-e39a-476f-ae9d-5ac46e7d969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = determine_location_status(grid, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e5dbe-2d8e-40a1-8b7b-d74904028c31",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# map of the urban and rural areas WorldPop\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 5))\n",
    "grid.sort_values(config.COL_LOC_ASSESSED, ascending=True).plot(\n",
    "    ax=ax2, column=config.COL_LOC_ASSESSED, cmap=\"Reds\", legend=True, alpha=0.5)\n",
    "ax2.set_aspect('equal', 'box')\n",
    "# txt = ax2.set_title('Urban and rural areas WorldPop in {} '.format(area))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2595faf-1b25-4043-ab1e-2e071b069248",
   "metadata": {},
   "source": [
    "#### Determine electrifed status of each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef04f6-7769-4672-ac84-fa8626001ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_electrification_status(grid_gdf, app_config, admin_gdf):\n",
    "    \"\"\"\n",
    "    Determines electrification status of grid cells based on proximity to MV/HV lines\n",
    "    and HREA (High Resolution Electricity Access) likelihood scores.\n",
    "\n",
    "    Args:\n",
    "        grid_gdf: GeoDataFrame of the hexagonal grid.\n",
    "        app_config: The configuration module.\n",
    "        admin_gdf: GeoDataFrame of admin boundaries \n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: grid_gdf with added columns for line proximity and electrification status.\n",
    "    \"\"\"\n",
    "    print(\"Determining electrification status...\")\n",
    "\n",
    "    # Load MV and HV lines\n",
    "    mv_lines_gdf = gpd.read_file(app_config.MV_LINES_SHP)\n",
    "    hv_lines_gdf = gpd.read_file(app_config.HV_LINES_SHP)\n",
    "    # print(f\"MV lines loaded: {mv_lines_gdf.shape}, HV lines loaded: {hv_lines_gdf.shape}\")\n",
    "\n",
    "    print(\"--- Initial Data Sanity Check ---\")\n",
    "    target_crs = config.TARGET_CRS_METERS\n",
    "    print(f\"Grid CRS: {grid_gdf.crs} | Shape: {grid_gdf.shape}\")\n",
    "    print(f\"Admin Boundary CRS: {admin_gdf.crs} | Shape: {admin_gdf.shape}\")\n",
    "    print(f\"MV Lines CRS: {mv_lines_gdf.crs} | Shape: {mv_lines_gdf.shape}\")\n",
    "    print(f\"HV Lines CRS: {hv_lines_gdf.crs} | Shape: {hv_lines_gdf.shape}\")\n",
    "    print(f\"Target CRS for all operations: {target_crs}\\n\")\n",
    "    # --- STEP 1: PROJECT ALL DATA TO THE TARGET CRS ---\n",
    "    # This ensures all subsequent operations (clip, buffer, sjoin) are in the same\n",
    "    # projected, meter-based coordinate system.\n",
    "    \n",
    "    print(\"--- Projecting all data to target CRS ---\")\n",
    "    grid_projected = grid_gdf.to_crs(target_crs)\n",
    "    admin_projected = admin_gdf.to_crs(target_crs)\n",
    "    # mv_lines_projected = mv_lines_gdf.to_crs(target_crs)\n",
    "    # hv_lines_projected = hv_lines_gdf.to_crs(target_crs)\n",
    "    \n",
    "    # Initialize the proximity column to False\n",
    "    grid_gdf[app_config.COL_IS_NEAR_ANY_LINE] = False\n",
    "\n",
    "    # Define line types and their specific buffer distances\n",
    "    lines_to_process = [\n",
    "        {'name': 'HV Lines', 'gdf': hv_lines_gdf, 'buffer_dist': app_config.HV_LINES_BUFFER_DIST},\n",
    "        {'name': 'MV Lines', 'gdf': mv_lines_gdf, 'buffer_dist': app_config.MV_LINES_BUFFER_DIST}\n",
    "    ]\n",
    "\n",
    "    for line_info in lines_to_process:\n",
    "        current_lines_gdf = line_info['gdf']\n",
    "        line_name = line_info['name']\n",
    "        buffer_dist = line_info['buffer_dist']\n",
    "        print(f\"Processing proximity for {line_name} with buffer {buffer_dist}m...\")\n",
    "\n",
    "        if current_lines_gdf.crs != target_crs:\n",
    "            lines_for_clip_and_buffer = current_lines_gdf.to_crs(target_crs)\n",
    "        else:\n",
    "            lines_for_clip_and_buffer = current_lines_gdf.copy()\n",
    "\n",
    "        # 1. Clip lines\n",
    "        clipped_lines_gdf = gpd.clip(lines_for_clip_and_buffer, admin_projected)\n",
    "        if clipped_lines_gdf.empty:\n",
    "            print(f\"No {line_name} found within the admin boundaries after clipping.\")\n",
    "            continue\n",
    "        \n",
    "        # 2. Buffer\n",
    "        buffered_lines = clipped_lines_gdf.buffer(buffer_dist)\n",
    "        if buffered_lines.is_empty.all():\n",
    "            print(f\"Buffer for {line_name} is empty. Skipping spatial join.\")\n",
    "            continue\n",
    "\n",
    "        # 3. Create a GeoDataFrame of the individual buffers\n",
    "        buffered_areas_gdf = gpd.GeoDataFrame(geometry=buffered_lines, crs=target_crs)\n",
    "\n",
    "        # 4. Perform the spatial join.\n",
    "        # Use an 'inner' join to get only the grid cells that intersect.\n",
    "        intersecting_grid = gpd.sjoin(grid_projected, buffered_areas_gdf, how='inner', predicate='intersects')\n",
    "\n",
    "        # Get the unique indices of the original grid cells that are near the lines\n",
    "        indices_to_update = intersecting_grid.index.unique()\n",
    "        \n",
    "        # 5. Update the 'is_near_any_line' column in the ORIGINAL grid.\n",
    "        grid_gdf.loc[indices_to_update, app_config.COL_IS_NEAR_ANY_LINE] = True\n",
    "    \n",
    "    print(f\"Updated 'is_near_any_line' column. Current counts:\")\n",
    "    print(grid_gdf['is_near_any_line'].value_counts())\n",
    "\n",
    "    if app_config.PROB_ELEC_COL not in grid_gdf.columns:\n",
    "        raise KeyError(f\"Required column '{app_config.PROB_ELEC_COL}' not found in grid.\")\n",
    "    if app_config.COL_LOC_ASSESSED not in grid_gdf.columns:\n",
    "        raise KeyError(f\"Required column '{app_config.COL_LOC_ASSESSED}' not found in grid.\")\n",
    "\n",
    "    # electrified or non-electrified status with thresholds depending on the location\n",
    "    threshold_map = {'urban': app_config.THRESHOLD_ELEC_ACCESS_URBAN, 'rural': app_config.THRESHOLD_ELEC_ACCESS_RURAL}\n",
    "    \n",
    "    grid_gdf[app_config.COL_STATUS_ELECTRIFIED] = grid_gdf.apply(\n",
    "        lambda row: \"elec\" if (\n",
    "            row[app_config.PROB_ELEC_COL] > threshold_map[row[app_config.COL_LOC_ASSESSED]] and\n",
    "            row[app_config.COL_IS_NEAR_ANY_LINE] \n",
    "        ) else \"nonelec\",\n",
    "        axis=1\n",
    "    )\n",
    "    print(f\"'{app_config.COL_STATUS_ELECTRIFIED}' column created. Counts: {grid_gdf[app_config.COL_STATUS_ELECTRIFIED].value_counts().to_dict()}\")\n",
    "    \n",
    "    return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba8032-da74-4c4b-899a-c286080dbf8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = determine_electrification_status(grid, config, admin_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742386c-c5fc-4a46-aaba-0d67eb008a27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# map of the lines\n",
    "fig3, ax3 = plt.subplots(figsize=(10, 5))\n",
    "grid.sort_values('is_near_any_line', ascending=True).plot(\n",
    "    ax=ax3, column='is_near_any_line', cmap=\"Reds\", legend=True, alpha=0.25)\n",
    "ax3.set_aspect('equal', 'box')\n",
    "lines_gdf.plot(ax=ax, edgecolor='purple', color='purple', alpha=0.4)\n",
    "# txt = ax3.set_title('Lines {} '.format(area))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc25805-0a35-498f-be63-54212aea6776",
   "metadata": {},
   "source": [
    "#### Assess number of households per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585bfa8-3b9c-4182-b8d7-7ad4669fa033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_household_numbers(grid_gdf, app_config, data_HH, regions_list):\n",
    "    \"\"\"\n",
    "    Calculates residential building counts and household numbers per grid cell.\n",
    "\n",
    "    It distinguishes between urban and rural areas and uses either provincial or \n",
    "    national level census data based on `app_config.PROVINCE_DATA_AVAILABLE`.\n",
    "    Calculates total population if provincial data (with household sizes) is used.\n",
    "\n",
    "    Args:\n",
    "        grid_gdf: GeoDataFrame of the hexagonal grid.\n",
    "        app_config: The configuration module.\n",
    "        data_HH: DataFrame with census data.\n",
    "        regions_list: List of region names being processed.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (grid_gdf, df_HH_buildings)\n",
    "               - grid_gdf: Updated grid GeoDataFrame with new household/population columns.\n",
    "               - df_HH_buildings: DataFrame summarizing household data by region (if provincial).\n",
    "                                  Returns None if national data is used.\n",
    "    \"\"\"\n",
    "    print(\"Calculating household numbers...\")\n",
    "    df_HH_buildings = None # Initialize for optional return\n",
    "\n",
    "    if app_config.PROVINCE_DATA_AVAILABLE:\n",
    "        data_buildings_list = []\n",
    "        for region_name in regions_list: \n",
    "            if app_config.COL_ADMIN_NAME not in grid_gdf.columns:\n",
    "                 raise KeyError(f\"Admin name column '{app_config.COL_ADMIN_NAME}' not found in grid for region filtering.\")\n",
    "\n",
    "            totalBuildings = grid_gdf[grid_gdf[app_config.COL_ADMIN_NAME] == region_name][app_config.COL_BUILDINGS_SUM].sum()\n",
    "            urbanBuildings = grid_gdf[(grid_gdf[app_config.COL_LOC_ASSESSED] == \"urban\") & (grid_gdf[app_config.COL_ADMIN_NAME] == region_name)][app_config.COL_BUILDINGS_SUM].sum()\n",
    "            ruralBuildings = grid_gdf[(grid_gdf[app_config.COL_LOC_ASSESSED] == \"rural\") & (grid_gdf[app_config.COL_ADMIN_NAME] == region_name)][app_config.COL_BUILDINGS_SUM].sum()\n",
    "            \n",
    "            data_region = {\n",
    "                'region': region_name,\n",
    "                'totalBuildings': totalBuildings,\n",
    "                'urbanBuildings': urbanBuildings if totalBuildings > 0 else 0,\n",
    "                'ruralBuildings': ruralBuildings if totalBuildings > 0 else 0,\n",
    "                'shareRuralBuild': ruralBuildings / totalBuildings if totalBuildings > 0 else 0,\n",
    "                'shareUrbanBuild': urbanBuildings / totalBuildings if totalBuildings > 0 else 0,\n",
    "            }\n",
    "            data_buildings_list.append(data_region)\n",
    "        \n",
    "        df_buildings = pd.DataFrame(data_buildings_list)\n",
    "        df_buildings.set_index('region', inplace=True)\n",
    "        df_HH_buildings = data_HH.merge(df_buildings, left_on='region', right_on='region', how='left')\n",
    "        \n",
    "        # Warning if mismatch happen            \n",
    "        # To avoid division by zero, we calculate the denominator first\n",
    "        denominator_rural = app_config.NB_OF_HH_PER_RES_BUILDING_URBAN * df_HH_buildings['urbanBuildings']\n",
    "        # Initialize the column with zeros\n",
    "        df_HH_buildings['shareUrbanResBui'] = 0.0\n",
    "        # Identify rows where the denominator is non-zero\n",
    "        valid_mask_rural = denominator_rural != 0\n",
    "        # Calculate the share only for valid rows\n",
    "        df_HH_buildings.loc[valid_mask_rural, 'shareUrbanResBui'] = df_HH_buildings.loc[valid_mask_rural, 'HH_urban'] / denominator_rural[valid_mask_rural]\n",
    "        \n",
    "        # --- Print data inconsistencies ---\n",
    "        invalid_mask = ~valid_mask_rural & (df_HH_buildings['HH_rural'] > 0)\n",
    "        if invalid_mask.any():\n",
    "            lost_hh = df_HH_buildings.loc[invalid_mask, 'HH_rural'].sum()\n",
    "            regions_affected = df_HH_buildings.loc[invalid_mask].index.tolist()\n",
    "            print(\n",
    "                f\"Data Inconsistency: {lost_hh:,.0f} urban households could not be allocated \"\n",
    "                f\"because no rural buildings were found in region(s): {regions_affected}. \"\n",
    "                f\"Their share is set to 0.\"\n",
    "            )\n",
    "        \n",
    "        df_HH_buildings['shareUrbanResBui'] = df_HH_buildings['HH_urban'] / (app_config.NB_OF_HH_PER_RES_BUILDING_URBAN * df_HH_buildings['urbanBuildings'])\n",
    "        df_HH_buildings['shareRuralResBui'] = df_HH_buildings['HH_rural'] / (app_config.NB_OF_HH_PER_RES_BUILDING_RURAL * df_HH_buildings['ruralBuildings'])\n",
    "            \n",
    "        df_HH_buildings.fillna(0, inplace=True)   \n",
    "\n",
    "        df_HH_buildings['resUrbanBui'] = df_HH_buildings['urbanBuildings'] * df_HH_buildings['shareUrbanResBui']\n",
    "        df_HH_buildings['resRuralBui'] = df_HH_buildings['ruralBuildings'] * df_HH_buildings['shareRuralResBui']\n",
    "        df_HH_buildings['resTotalBui'] = df_HH_buildings['resUrbanBui'] + df_HH_buildings['resRuralBui']\n",
    "\n",
    "        # if not app_config.COL_ADMIN_NAME in df_HH_buildings.index:\n",
    "        #     raise KeyError(f\"Required column '{app_config.COL_ADMIN_NAME}' not found in census data.\")\n",
    "        \n",
    "        grid_gdf[app_config.COL_RES_URBAN_BUI] = grid_gdf.apply(\n",
    "            lambda row: row[app_config.COL_BUILDINGS_SUM] * df_HH_buildings.loc[row[app_config.COL_ADMIN_NAME], 'shareUrbanResBui'] \n",
    "                        if row[app_config.COL_LOC_ASSESSED] == 'urban' else 0, axis=1\n",
    "        )\n",
    "        grid_gdf[app_config.COL_RES_RURAL_BUI] = grid_gdf.apply(\n",
    "            lambda row: row[app_config.COL_BUILDINGS_SUM] * df_HH_buildings.loc[row[app_config.COL_ADMIN_NAME], 'shareRuralResBui'] \n",
    "                        if row[app_config.COL_LOC_ASSESSED] == 'rural' else 0, axis=1\n",
    "        )\n",
    "    else: \n",
    "        totalBuildings = grid_gdf[app_config.COL_BUILDINGS_SUM].sum()\n",
    "        urbanBuildings = grid_gdf[grid_gdf[app_config.COL_LOC_ASSESSED] == \"urban\"][app_config.COL_BUILDINGS_SUM].sum()\n",
    "        ruralBuildings = grid_gdf[grid_gdf[app_config.COL_LOC_ASSESSED] == \"rural\"][app_config.COL_BUILDINGS_SUM].sum()\n",
    "\n",
    "        nat_HH_urban = data_HH['Urban'].iloc[0]\n",
    "        nat_HH_rural = data_HH['Rural'].iloc[0]\n",
    "\n",
    "        shareResBui_urban = nat_HH_urban / (app_config.NB_OF_HH_PER_RES_BUILDING_URBAN * urbanBuildings) if urbanBuildings > 0 else 0\n",
    "        shareResBui_rural = nat_HH_rural / (app_config.NB_OF_HH_PER_RES_BUILDING_RURAL * ruralBuildings) if ruralBuildings > 0 else 0\n",
    "        \n",
    "        grid_gdf[app_config.COL_RES_URBAN_BUI] = grid_gdf.apply(\n",
    "            lambda row: row[app_config.COL_BUILDINGS_SUM] * shareResBui_urban if row[app_config.COL_LOC_ASSESSED] == 'urban' else 0, axis=1\n",
    "        )\n",
    "        grid_gdf[app_config.COL_RES_RURAL_BUI] = grid_gdf.apply(\n",
    "            lambda row: row[app_config.COL_BUILDINGS_SUM] * shareResBui_rural if row[app_config.COL_LOC_ASSESSED] == 'rural' else 0, axis=1\n",
    "        )\n",
    "\n",
    "    grid_gdf[app_config.COL_RES_BUI] = grid_gdf[app_config.COL_RES_URBAN_BUI] + grid_gdf[app_config.COL_RES_RURAL_BUI]\n",
    "    grid_gdf[app_config.COL_HH_URBAN] = (grid_gdf[app_config.COL_RES_URBAN_BUI] * app_config.NB_OF_HH_PER_RES_BUILDING_URBAN).fillna(0)\n",
    "    grid_gdf[app_config.COL_HH_RURAL] = (grid_gdf[app_config.COL_RES_RURAL_BUI] * app_config.NB_OF_HH_PER_RES_BUILDING_RURAL).fillna(0)\n",
    "    grid_gdf[app_config.COL_HH_TOTAL] = grid_gdf[app_config.COL_HH_URBAN] + grid_gdf[app_config.COL_HH_RURAL]\n",
    "\n",
    "    if app_config.PROVINCE_DATA_AVAILABLE:\n",
    "        if not all(f\"size_HH_{loc}\" in data_HH.columns for loc in [\"urban\", \"rural\"]):\n",
    "            raise KeyError(\"Missing 'size_HH_urban' or 'size_HH_rural' in census data for population calculation.\")\n",
    "\n",
    "        get_size_HH = lambda row: data_HH.loc[row[app_config.COL_ADMIN_NAME], f\"size_HH_{row[app_config.COL_LOC_ASSESSED]}\"] \\\n",
    "                                  if row[app_config.COL_ADMIN_NAME] in data_HH.index else np.nan\n",
    "        grid_gdf[app_config.COL_POP_URBAN] = grid_gdf[app_config.COL_HH_URBAN] * grid_gdf.apply(get_size_HH, axis=1)\n",
    "        grid_gdf[app_config.COL_POP_RURAL] = grid_gdf[app_config.COL_HH_RURAL] * grid_gdf.apply(get_size_HH, axis=1)\n",
    "        grid_gdf[app_config.COL_POPULATION] = grid_gdf[app_config.COL_POP_URBAN] + grid_gdf[app_config.COL_POP_RURAL]\n",
    "        total_population = grid_gdf[app_config.COL_POPULATION].sum()\n",
    "        print(f\"Total population calculated: {total_population:,.0f}\")\n",
    "\n",
    "    print(\"Finished calculating household numbers.\")\n",
    "    return grid_gdf, df_HH_buildings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2960a-620c-4776-8d80-944cc804a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, df_HH_buildings = calculate_household_numbers(grid, config, data_HH, regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a576ba-d58c-4edf-8540-27769366f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HH_buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110c32f-b4f8-41ea-b27c-d4dcdccc62e0",
   "metadata": {},
   "source": [
    "#### Assess number of households per cell with access to electricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a22a9-d592-4bd8-b2c8-5712dceb2dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_hh_with_access(grid_gdf, app_config, df_HH_buildings, data_HH):\n",
    "    \"\"\"\n",
    "    Estimates the number of households with electricity access and calculates access rates.\n",
    "\n",
    "    Updates grid_gdf with columns for households with and without access.\n",
    "    If provincial data is available,\n",
    "    this DataFrame is updated with regional access summaries and saved to a CSV.\n",
    "\n",
    "    Args:\n",
    "        grid_gdf: GeoDataFrame of the hexagonal grid.\n",
    "        app_config: The configuration module.\n",
    "        df_HH_buildings: DataFrame for regional household summaries.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (grid_gdf, df_HH_buildings)\n",
    "               - grid_gdf: Updated grid GeoDataFrame.\n",
    "               - df_HH_buildings: Updated regional summary DataFrame (or None).\n",
    "    \"\"\"\n",
    "    print(\"Estimating households with access...\")\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    required_cols = [app_config.COL_HH_URBAN, app_config.COL_HH_RURAL, \n",
    "                     app_config.PROB_ELEC_COL, app_config.COL_STATUS_ELECTRIFIED]\n",
    "    for col in required_cols:\n",
    "        if col not in grid_gdf.columns:\n",
    "            raise KeyError(f\"Required column '{col}' not found in grid_gdf for HH access calculation.\")\n",
    "\n",
    "    grid_gdf[app_config.COL_HH_WITH_ACCESS_URB] = (\n",
    "        grid_gdf[app_config.COL_HH_URBAN] *\n",
    "        grid_gdf[app_config.PROB_ELEC_COL] *\n",
    "        (grid_gdf[app_config.COL_STATUS_ELECTRIFIED] == 'elec') *\n",
    "        app_config.CORRECTION_FACTOR_URBAN_HH_ACCESS\n",
    "    )\n",
    "    grid_gdf[app_config.COL_HH_WITH_ACCESS_RUR] = (\n",
    "        grid_gdf[app_config.COL_HH_RURAL] *\n",
    "        grid_gdf[app_config.PROB_ELEC_COL] *\n",
    "        (grid_gdf[app_config.COL_STATUS_ELECTRIFIED] == 'elec')\n",
    "    )\n",
    "    grid_gdf[app_config.COL_HH_WITH_ACCESS] = grid_gdf[app_config.COL_HH_WITH_ACCESS_URB] + grid_gdf[app_config.COL_HH_WITH_ACCESS_RUR]\n",
    "    \n",
    "    # HH without access\n",
    "    grid_gdf[app_config.COL_HH_WO_ACCESS_URB] = grid_gdf[app_config.COL_HH_URBAN] - grid_gdf[app_config.COL_HH_WITH_ACCESS_URB]\n",
    "    grid_gdf[app_config.COL_HH_WO_ACCESS_RUR] = grid_gdf[app_config.COL_HH_RURAL] - grid_gdf[app_config.COL_HH_WITH_ACCESS_RUR]\n",
    "    grid_gdf[app_config.COL_HH_WO_ACCESS] = grid_gdf[app_config.COL_HH_WO_ACCESS_URB] + grid_gdf[app_config.COL_HH_WO_ACCESS_RUR]\n",
    "\n",
    "    if app_config.PROVINCE_DATA_AVAILABLE and df_HH_buildings is not None:\n",
    "        print(\"Aggregating HH access data by region...\")\n",
    "        # Aggregate HH with access by region\n",
    "        totalHHWithAccessUrb = grid_gdf.groupby(app_config.COL_ADMIN_NAME)[app_config.COL_HH_WITH_ACCESS_URB].sum()\n",
    "        totalHHWithAccessRur = grid_gdf.groupby(app_config.COL_ADMIN_NAME)[app_config.COL_HH_WITH_ACCESS_RUR].sum()\n",
    "        totalHHWithAccess = grid_gdf.groupby(app_config.COL_ADMIN_NAME)[app_config.COL_HH_WITH_ACCESS].sum()\n",
    "\n",
    "        df_HH_access_summary = pd.DataFrame({\n",
    "            app_config.COL_HH_WITH_ACCESS_URB: totalHHWithAccessUrb,\n",
    "            app_config.COL_HH_WITH_ACCESS_RUR: totalHHWithAccessRur,\n",
    "            app_config.COL_HH_WITH_ACCESS: totalHHWithAccess,\n",
    "        })\n",
    "        df_HH_access_summary.rename_axis('region', inplace=True)\n",
    "        # Merge with df_HH_buildings\n",
    "        df_HH_buildings = df_HH_buildings.merge(df_HH_access_summary, left_index=True, right_index=True)\n",
    "        \n",
    "        # Calculate population with access (requires df_censusdata for HH size)\n",
    "        # This part might be better placed if df_censusdata is passed directly, or HH size is already in df_HH_buildings_optional\n",
    "        if app_config.COL_POPULATION in grid_gdf.columns: # Check if population was calculated\n",
    "            get_size_HH = lambda row: data_HH.loc[row[app_config.COL_ADMIN_NAME], f\"size_HH_{row[app_config.COL_LOC_ASSESSED]}\"] \\\n",
    "                                  if row[app_config.COL_ADMIN_NAME] in data_HH.index else np.nan\n",
    "            grid_gdf['population_urban_withAccess'] = grid_gdf[app_config.COL_POPULATION] * grid_gdf.apply(get_size_HH, axis=1).replace([np.inf, -np.inf, np.nan], 0)\n",
    "            grid_gdf['population_rural_withAccess'] = grid_gdf[app_config.COL_POPULATION] * grid_gdf.apply(get_size_HH, axis=1).replace([np.inf, -np.inf, np.nan], 0)\n",
    "            grid_gdf['population_withAccess'] = grid_gdf['population_urban_withAccess'] + grid_gdf['population_rural_withAccess']\n",
    "            total_population_withAccess = grid_gdf['population_withAccess'].sum()\n",
    "            print(f\"Total population with access (estimated): {total_population_withAccess:,.0f}\")\n",
    "        \n",
    "        # Calculate access rates in df_HH_buildings\n",
    "        df_HH_buildings['accessRateHH'] = (df_HH_buildings[app_config.COL_HH_WITH_ACCESS] / df_HH_buildings['HH_total']).replace([np.inf, -np.inf, np.nan], 0)\n",
    "        df_HH_buildings['accessRateHH_urban'] = (df_HH_buildings[app_config.COL_HH_WITH_ACCESS_URB] / df_HH_buildings['HH_urban']).replace([np.inf, -np.inf, np.nan], 0)\n",
    "        df_HH_buildings['accessRateHH_rural'] = (df_HH_buildings[app_config.COL_HH_WITH_ACCESS_RUR] / df_HH_buildings['HH_rural']).replace([np.inf, -np.inf, np.nan], 0)\n",
    "        \n",
    "        # Add national summary to df_HH_buildings\n",
    "        if not df_HH_buildings.empty:\n",
    "            df_sum = df_HH_buildings[[col for col in df_HH_buildings.columns if col != app_config.COL_ADMIN_NAME]].sum(axis=0, numeric_only=True)\n",
    "            df_sum[app_config.COL_ADMIN_NAME] = 'National'\n",
    "            # Recalculate rates for National summary\n",
    "            df_sum['accessRateHH'] = df_sum[app_config.COL_HH_WITH_ACCESS] / df_sum['HH_total']\n",
    "            df_sum['accessRateHH_urban'] = df_sum[app_config.COL_HH_WITH_ACCESS_URB] / df_sum['HH_urban']\n",
    "            df_sum['accessRateHH_rural'] = df_sum[app_config.COL_HH_WITH_ACCESS_RUR] / df_sum['HH_rural']\n",
    "            df_sum = pd.DataFrame(df_sum).T.set_index(app_config.COL_ADMIN_NAME)\n",
    "            df_HH_buildings = pd.concat([df_HH_buildings, df_sum])\n",
    "\n",
    "        output_csv_path = os.path.join(app_config.RESIDENTIAL_OUTPUT_DIR, \"dataHH_region.csv\")\n",
    "        df_HH_buildings.to_csv(output_csv_path, index=True)\n",
    "        print(f\"Regional HH summary saved to {output_csv_path}\")\n",
    "        print(df_HH_buildings[['accessRateHH','accessRateHH_urban','accessRateHH_rural']].tail())\n",
    "\n",
    "\n",
    "    print(\"Finished estimating households with access.\")\n",
    "    return grid_gdf, df_HH_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce9d6d-74f6-4cfb-ba53-44e695fc3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, df_HH_buildings = estimate_hh_with_access(grid, config, df_HH_buildings, data_HH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc65e3-fd9a-46c2-89ec-896b1f9a524d",
   "metadata": {},
   "source": [
    "### Step 2: assess the electricity consumption per HH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0db2df-617c-4741-b792-a3c7b6d88348",
   "metadata": {},
   "source": [
    "#### Method 1: link the energy consumption to rwi through a logistic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c9f538-147d-4896-850c-d651937469ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the rwi index\n",
    "rwi_min = grid['rwi'].min()\n",
    "rwi_max = grid['rwi'].max()\n",
    "grid['rwi_norm'] = (grid['rwi'] - rwi_min) / (rwi_max - rwi_min)\n",
    "grid['rwi_norm'].plot.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32efd72e-b798-41fc-966a-00665d97c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of number of HH vs rwi\n",
    "\n",
    "# Create equally spaced bins for the 'rwi' values\n",
    "num_groups = 100\n",
    "min_rwi = grid['rwi_norm'].min()\n",
    "max_rwi = grid['rwi_norm'].max()\n",
    "bin_width = (max_rwi - min_rwi) / num_groups\n",
    "rwi_bins = [min_rwi + i * bin_width for i in range(num_groups + 1)]\n",
    "rwi_bins_labels = [(rwi_bins[i] + rwi_bins[i])/2 for i in range(num_groups)]\n",
    "\n",
    "# Group by the bins and sum the 'HH_total' values\n",
    "grid['rwi_group'] = pd.cut(grid['rwi_norm'], rwi_bins)\n",
    "result = grid.groupby('rwi_group')['HH_total'].sum()\n",
    "result.index = result.index.astype(str)\n",
    "# # Print the result\n",
    "# print(result)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(result.index, result.values, color='skyblue', edgecolor='black')\n",
    "# plt.bar(rwi_bins_labels, result.values, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('RWI Value Groups')\n",
    "plt.ylabel('Total HH_total')\n",
    "plt.title('Sum of HH_total by RWI Value Groups')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653931a-5e4f-454d-bede-8ddf7614754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of number of HH with access vs rwi\n",
    "\n",
    "# Group by the bins and sum the 'HHwithAccess' values\n",
    "result = grid.groupby('rwi_group')['HHwithAccess'].sum()\n",
    "result.index = result.index.astype(str)\n",
    "# # Print the result\n",
    "# print(result)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(result.index, result.values, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('RWI Value Groups')\n",
    "plt.ylabel('Total HH with access')\n",
    "plt.title('Sum of HH with access by RWI Value Groups')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ee401-25d2-45ef-b9a1-f536eda3d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_energy_per_hh_method1(grid_gdf, app_config, total_residential_elec_GWh):\n",
    "    \"\"\"\n",
    "    Calculates energy per household using RWI-based logistic function\n",
    "\n",
    "    This method normalizes the Relative Wealth Index (RWI), then solves for a \n",
    "    parameter `k` in a logistic function to ensure the total calculated energy \n",
    "    matches UN statistics. It adds a column for the calculated energy per household.\n",
    "\n",
    "    Args:\n",
    "        grid_gdf: GeoDataFrame of the hexagonal grid.\n",
    "        app_config: The configuration module.\n",
    "        total_residential_energy_gwh: Total national residential energy (GWh) from UN stats.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: grid_gdf with added column for energy per household (Method 1).\n",
    "    \"\"\"\n",
    "    print(\"Calculating energy per HH (Method 1: RWI-logistic)...\")\n",
    "    \n",
    "    if app_config.COL_RWI_MEAN not in grid_gdf.columns:\n",
    "        raise KeyError(f\"Required column '{app_config.COL_RWI_MEAN}' not found for RWI normalization.\")\n",
    "\n",
    "    rwi_min = grid_gdf[app_config.COL_RWI_MEAN].min()\n",
    "    rwi_max = grid_gdf[app_config.COL_RWI_MEAN].max()\n",
    "    if (rwi_max - rwi_min) == 0: \n",
    "        grid_gdf[app_config.COL_RWI_NORM] = 0.5 \n",
    "        print(\"Warning: RWI min and max are equal. Normalized RWI set to 0.5.\")\n",
    "    else:\n",
    "        grid_gdf[app_config.COL_RWI_NORM] = (grid_gdf[app_config.COL_RWI_MEAN] - rwi_min) / (rwi_max - rwi_min)\n",
    "\n",
    "    alpha = app_config.LOGISTIC_E_THRESHOLD / app_config.LOGISTIC_ALPHA_DERIVATION_THRESHOLD - 1\n",
    "    \n",
    "    if app_config.COL_HH_WITH_ACCESS not in grid_gdf.columns:\n",
    "        raise KeyError(f\"Required column '{app_config.COL_HH_WITH_ACCESS}' not found for fsolve.\")\n",
    "\n",
    "    def func_solve_k(k_var):\n",
    "        # Calculates total energy based on k_var and compares to UN total.\n",
    "        e_hh = app_config.LOGISTIC_E_THRESHOLD / (1 + alpha * np.exp(-k_var * grid_gdf[app_config.COL_RWI_NORM]))\n",
    "        res_energy_assessed = (e_hh * grid_gdf[app_config.COL_HH_WITH_ACCESS]).sum()\n",
    "        return res_energy_assessed / 1e6 - total_residential_elec_GWh # kWh to GWh\n",
    "\n",
    "    try:\n",
    "        k_solution = fsolve(func_solve_k, app_config.LOGISTIC_K_INITIAL_GUESS)\n",
    "        # print(f\"Solved k for logistic function: {k_solution[0]:.4f}\")\n",
    "        k_to_use = k_solution[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error solving for k in RWI-logistic method: {e}. Using initial guess: {app_config.LOGISTIC_K_INITIAL_GUESS}\")\n",
    "        k_to_use = app_config.LOGISTIC_K_INITIAL_GUESS\n",
    "        \n",
    "    grid_gdf[app_config.COL_RES_ELEC_PER_HH_LOG] = app_config.LOGISTIC_E_THRESHOLD / (\n",
    "        1 + alpha * np.exp(-k_to_use * grid_gdf[app_config.COL_RWI_NORM])\n",
    "    )\n",
    "    print(\"Finished calculating energy per HH (Method 1).\")\n",
    "    return grid_gdf, k_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ccafc-cd34-4d96-ac70-1bbe535b8c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, k_to_use = calculate_energy_per_hh_method1(grid, config, total_residential_elec_GWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5eb82-b49d-4d15-b8f1-1a4ed6bc4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the curve linking energy consumption per HH and rwi\n",
    "rwi_values = rwi_bins # rwi value groups\n",
    "k = k_to_use  # Adjust this constant for the desired curve steepness\n",
    "E_threshold = config.LOGISTIC_E_THRESHOLD\n",
    "alpha = config.LOGISTIC_E_THRESHOLD / config.LOGISTIC_ALPHA_DERIVATION_THRESHOLD - 1\n",
    "E_HH_values = config.LOGISTIC_E_THRESHOLD / (1 + alpha * np.exp(-k * np.array(rwi_values)))\n",
    "# print(E_threshold / (1 + alpha * np.exp(-k  * 0)))\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(rwi_values, E_HH_values, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('RWI Value Groups')\n",
    "plt.ylabel('Electricity consumption per household')\n",
    "ax = plt.gca()  # Get the current axis\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "# plt.title('Energy vs. RWI with logistic relationship')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e7f5cc-f559-40bf-8a65-76adcc63c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that total energy assessed matches the statistics\n",
    "grid['ResEnergyPerHH_log'] = E_threshold / (1 + alpha * np.exp(-k * grid['rwi_norm']))\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(grid['rwi_norm'], grid['ResEnergyPerHH_log'], color='skyblue', edgecolor='black')\n",
    "plt.xlabel('normalised RWI')\n",
    "plt.ylabel('Electricity consumption per household (kWh)')\n",
    "ax = plt.gca()  # Get the current axis\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "# plt.title('Energy vs. RWI with Logarithmic Relationship')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7af71f-1013-401b-828f-50db4e8609e9",
   "metadata": {},
   "source": [
    "#### Method 2: use data coming from the DHS survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8b7ecc-dc47-469f-bb42-d48d59af9ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_energy_per_hh_method2(grid_gdf, app_config, estimate_energy_func):\n",
    "    \"\"\"\n",
    "    Calculates energy per household using Method 2 (DHS survey-based).\n",
    "\n",
    "    This method calls an external script (`estimate_energy_rwi_link_national`)\n",
    "    which processes DHS data to link RWI and electricity access to electricity consumption.\n",
    "\n",
    "    Args:\n",
    "        grid_gdf: GeoDataFrame of the hexagonal grid.\n",
    "        app_config: The configuration module.\n",
    "        estimate_energy_func: The imported `estimate_energy_rwi_link_national` function.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: grid_gdf with added column for electricity per household (Method 2).\n",
    "    \"\"\"\n",
    "    print(\"Calculating energy per HH (Method 2: DHS-based)...\")\n",
    "    \n",
    "    dhs_survey_folder = os.path.join(app_config.RESIDENTIAL_DATA_PATH, \"DHSSurvey/\")\n",
    "    \n",
    "    grid_gdf = estimate_energy_func(\n",
    "        grid_gdf,\n",
    "        dhs_survey_folder, \n",
    "        app_config.FIGURES_DHS_FOLDER, \n",
    "        make_figure=app_config.DHS_MAKE_FIGURE,\n",
    "        recalculate_energies=app_config.DHS_RECALCULATE_ENERGIES,\n",
    "        simulate_cell_groups=app_config.DHS_SIMULATE_CELL_GROUPS,\n",
    "        recalculate_energy_perhh=app_config.DHS_RECALCULATE_ENERGY_PERHH\n",
    "    )\n",
    "    \n",
    "    col_elec_rural = 'elec_demand_kWh_rural' \n",
    "    col_elec_urban = 'elec_demand_kWh_urban' \n",
    "    \n",
    "    if col_elec_rural not in grid_gdf.columns or col_elec_urban not in grid_gdf.columns:\n",
    "        raise KeyError(f\"Expected columns '{col_elec_rural}' or '{col_elec_urban}' not found after DHS estimation.\")\n",
    "        \n",
    "    grid_gdf[app_config.COL_RES_ELEC_PER_HH_DHS] = grid_gdf[col_elec_rural] + grid_gdf[col_elec_urban]\n",
    "    \n",
    "    print(\"Finished calculating energy per HH (Method 2).\")\n",
    "    return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3889a5-178c-4d62-a89c-4cdc4d05227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Residential.HouseholdEnergyUse.estimate_energy_rwi_link_national_new\n",
    "\n",
    "# 1. Reload the entire module file\n",
    "importlib.reload(Residential.HouseholdEnergyUse.estimate_energy_rwi_link_national_new)\n",
    "\n",
    "# 2. After reloading, re-import the specific function to get the updated version\n",
    "from Residential.HouseholdEnergyUse.estimate_energy_rwi_link_national_new import estimate_energy_rwi_link_national\n",
    "grid = calculate_energy_per_hh_method2(grid, config, estimate_energy_rwi_link_national)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde7d73-e522-4786-9781-7559886b6903",
   "metadata": {},
   "source": [
    "### Step 3: assess electricity consumption per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7d1bc5-416c-4acb-89ec-65ad7a4ecae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_residential_electricity(grid_gdf, app_config, total_residential_energy_gwh):\n",
    "    \"\"\"\n",
    "    Calculates total residential energy per cell for different methods and scales to UN stats.\n",
    "\n",
    "    This function takes the per-household energy estimates from Method 1 (RWI-logistic)\n",
    "    and Method 2 (DHS-based), calculates the total energy per grid cell for each method,\n",
    "    and then scales these totals so that the national aggregate matches UN statistics.\n",
    "\n",
    "    Args:\n",
    "        grid_gdf: GeoDataFrame of the hexagonal grid with per-HH energy estimates.\n",
    "        app_config: The configuration module.\n",
    "        total_residential_energy_gwh: Total national residential energy (GWh) from UN stats.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: grid_gdf with added columns for raw and scaled total residential energy.\n",
    "    \"\"\"\n",
    "    print(\"Calculating total residential energy and scaling...\")\n",
    "\n",
    "    # Ensure required input columns exist\n",
    "    required_cols_meth1 = [app_config.COL_RES_ELEC_PER_HH_LOG, app_config.COL_HH_WITH_ACCESS]\n",
    "    required_cols_meth2 = [app_config.COL_RES_ELEC_PER_HH_DHS, app_config.COL_HH_WITH_ACCESS]\n",
    "    \n",
    "    for col in required_cols_meth1:\n",
    "        if col not in grid_gdf.columns: raise KeyError(f\"Method 1: Column '{col}' not found.\")\n",
    "    for col in required_cols_meth2:\n",
    "        if col not in grid_gdf.columns: raise KeyError(f\"Method 2: Column '{col}' not found.\")\n",
    "\n",
    "    # For method 1, assign electricity per HH where access > 0, else 0\n",
    "    grid_gdf[\"ElecPerHH_kWh_meth1\"] = grid_gdf.apply(\n",
    "        lambda row: row[app_config.COL_RES_ELEC_PER_HH_LOG] if row[app_config.COL_HH_WITH_ACCESS] > 0 else 0, axis=1\n",
    "    )\n",
    "    # For method 2, the ElectricityPerHH_DHS is already calculated considering access within its script.\n",
    "    grid_gdf[\"ElecPerHH_kWh_meth2\"] = grid_gdf[app_config.COL_RES_ELEC_PER_HH_DHS]\n",
    "\n",
    "    methods_map = {\n",
    "        'meth1': {'per_hh_col': \"ElecPerHH_kWh_meth1\", 'output_col_scaled': app_config.COL_RES_ELEC_KWH_METH1_SCALED, 'raw_total_col': app_config.COL_RES_ELEC_KWH_METH1},\n",
    "        'meth2': {'per_hh_col': \"ElecPerHH_kWh_meth2\", 'output_col_scaled': app_config.COL_RES_ELEC_KWH_METH2_SCALED, 'raw_total_col': app_config.COL_RES_ELEC_KWH_METH2}\n",
    "    }\n",
    "\n",
    "    results_beforescaling_summary = {}\n",
    "    results_afterscaling_summary = {}\n",
    "\n",
    "    for method_key, details in methods_map.items():\n",
    "        # Calculate raw total energy per cell (kWh)\n",
    "        grid_gdf[details['raw_total_col']] = grid_gdf[app_config.COL_HH_WITH_ACCESS] * grid_gdf[details['per_hh_col']]\n",
    "        \n",
    "        # Aggregate by administrative region (e.g., NAME_1) if COL_ADMIN_NAME is present\n",
    "        if app_config.COL_ADMIN_NAME in grid_gdf.columns:\n",
    "            regional_sum_gwh = grid_gdf.groupby(app_config.COL_ADMIN_NAME)[details['raw_total_col']].sum() / 10**6 # kWh to GWh\n",
    "            results_beforescaling_summary[method_key] = regional_sum_gwh\n",
    "            total_assessed_gwh = regional_sum_gwh.sum()\n",
    "        else: # No admin column, sum all cells\n",
    "            total_assessed_gwh = grid_gdf[details['raw_total_col']].sum() / 10**6 # kWh to GWh\n",
    "            results_beforescaling_summary[method_key] = pd.Series({\"National\": total_assessed_gwh})\n",
    "\n",
    "\n",
    "        if total_assessed_gwh == 0:\n",
    "            print(f\"Warning: Total assessed energy for {method_key} is 0. Scaling factor cannot be computed. Scaled energy will be 0.\")\n",
    "            scaling_factor = 0\n",
    "        else:\n",
    "            scaling_factor = total_residential_energy_gwh / total_assessed_gwh\n",
    "        \n",
    "        print(f\"Method {method_key}: Total Assessed = {total_assessed_gwh:.2f} GWh, UN Stats = {total_residential_energy_gwh:.2f} GWh, Scaling Factor = {scaling_factor:.4f}\")\n",
    "\n",
    "        grid_gdf[details['output_col_scaled']] = grid_gdf[details['raw_total_col']] * scaling_factor\n",
    "        \n",
    "        if app_config.COL_ADMIN_NAME in grid_gdf.columns:\n",
    "            results_afterscaling_summary[method_key] = grid_gdf.groupby(app_config.COL_ADMIN_NAME)[details['output_col_scaled']].sum() / 10**6\n",
    "        else:\n",
    "            results_afterscaling_summary[method_key] = pd.Series({\"National\": grid_gdf[details['output_col_scaled']].sum() / 10**6})\n",
    "\n",
    "    print(\"\\nSummary of energy consumption before scaling (GWh):\")\n",
    "    print(pd.DataFrame(results_beforescaling_summary))\n",
    "    print(\"\\nSummary of energy consumption after scaling (GWh):\")\n",
    "    print(pd.DataFrame(results_afterscaling_summary))\n",
    "    \n",
    "    print(\"Finished calculating and scaling total residential energy.\")\n",
    "    return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a85e64-0f18-41fd-bb62-a98023bca811",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = calculate_total_residential_electricity(grid, config, total_residential_elec_GWh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dc5645-eeb5-48c0-98d8-bac57de05bca",
   "metadata": {},
   "source": [
    "### Compare access rates to Falchetta dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee741fe9-c66f-4ddd-b94b-a07be99a69ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_access_to_falchetta(grid_gdf, app_config):\n",
    "    \"\"\"\n",
    "    Compares calculated residential energy consumption tiers with Falchetta dataset tiers.\n",
    "\n",
    "    This function bins calculated per-household energy into tiers and compares the \n",
    "    distribution of households across these tiers against pre-loaded Falchetta tier data.\n",
    "    It also performs a similarity analysis between the DHS-based calculated tiers and \n",
    "    Falchetta's majority tier.\n",
    "\n",
    "    Args:\n",
    "        grid_gdf: GeoDataFrame of the hexagonal grid with energy consumption data.\n",
    "        app_config: The configuration module.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: grid_gdf, potentially with added columns for tiering/comparison.\n",
    "    \"\"\"\n",
    "    print(\"Comparing access tiers to Falchetta dataset...\")\n",
    "\n",
    "    def calculate_tier_share_method(data_grid, method_suffix, hh_with_access_col, hh_wo_access_col, category_total_val):\n",
    "        # Helper for tier share calculation\n",
    "        tier_col_name = f'tiers_{method_suffix}' \n",
    "        if tier_col_name not in data_grid.columns:\n",
    "            # print(f\"Warning: Tier column '{tier_col_name}' not found for method '{method_suffix}'.\")\n",
    "            return pd.Series(dtype=float)\n",
    "        if category_total_val == 0: return pd.Series(dtype=float)\n",
    "\n",
    "        tier_share = data_grid.groupby(tier_col_name)[hh_with_access_col].sum()\n",
    "        if 0 in tier_share.index :\n",
    "            tier_share.loc[0] += data_grid[hh_wo_access_col].sum()\n",
    "        else: \n",
    "            tier_share.loc[0] = data_grid[hh_wo_access_col].sum()\n",
    "        return tier_share.sort_index() / category_total_val\n",
    "\n",
    "    bins_tiers = app_config.BINS_TIERS_ENERGY\n",
    "    tier_labels = range(len(bins_tiers) - 1)\n",
    "\n",
    "    categories_summary = {\n",
    "        'national': app_config.COL_HH_TOTAL, 'urban': app_config.COL_HH_URBAN, 'rural': app_config.COL_HH_RURAL\n",
    "    }\n",
    "\n",
    "    # Falchetta dataset\n",
    "    for col_type in [app_config.COL_TIERS_FALCHETTA_MAJ, app_config.COL_TIERS_FALCHETTA_MEAN]:\n",
    "        if col_type in grid_gdf.columns:\n",
    "            tiers_summary_df = pd.DataFrame()\n",
    "            for cat_name, total_hh_col in categories_summary.items():\n",
    "                 if total_hh_col in grid_gdf.columns and grid_gdf[total_hh_col].sum() > 0:\n",
    "                    cat_sum = grid_gdf.groupby(col_type)[total_hh_col].sum()\n",
    "                    tiers_summary_df[cat_name] = cat_sum / cat_sum.sum()\n",
    "            print(f\"\\nFalchetta Tiers Summary ({col_type}):\")\n",
    "            print(tiers_summary_df.fillna(0))\n",
    "    \n",
    "    # Our methods\n",
    "    methods_to_compare = {\n",
    "        'meth1': app_config.COL_RES_ELEC_PER_HH_LOG,\n",
    "        'meth2': \"ElecPerHH_kWh_meth2\" \n",
    "    }\n",
    "    categories_for_comparison = [\n",
    "        ('national', app_config.COL_HH_WITH_ACCESS, app_config.COL_HH_WO_ACCESS, app_config.COL_HH_TOTAL),\n",
    "        ('urban', app_config.COL_HH_WITH_ACCESS_URB, app_config.COL_HH_WO_ACCESS_URB, app_config.COL_HH_URBAN),\n",
    "        ('rural', app_config.COL_HH_WITH_ACCESS_RUR, app_config.COL_HH_WO_ACCESS_RUR, app_config.COL_HH_RURAL)\n",
    "    ]\n",
    "\n",
    "    for method_key, energy_col_name in methods_to_compare.items():\n",
    "        if energy_col_name not in grid_gdf.columns:\n",
    "            print(f\"Warning: Energy column '{energy_col_name}' for method '{method_key}' not found.\")\n",
    "            continue\n",
    "        \n",
    "        grid_gdf[f'tiers_{method_key}'] = pd.cut(grid_gdf[energy_col_name], bins=bins_tiers, labels=tier_labels, right=False)\n",
    "        grid_gdf[f'tiers_{method_key}'] = grid_gdf[f'tiers_{method_key}'].fillna(0).astype(int)\n",
    "\n",
    "        df_tiers_data = pd.DataFrame()\n",
    "        for cat_name, hh_access_col, hh_no_access_col, total_hh_col in categories_for_comparison:\n",
    "            if all(c in grid_gdf.columns for c in [hh_access_col, hh_no_access_col, total_hh_col]):\n",
    "                cat_total_val = grid_gdf[total_hh_col].sum()\n",
    "                if cat_total_val > 0:\n",
    "                    tier_share_series = calculate_tier_share_method(grid_gdf, method_key, hh_access_col, hh_no_access_col, cat_total_val)\n",
    "                    df_tiers_data[cat_name] = tier_share_series\n",
    "        \n",
    "        print(f\"\\nTier Shares for Method '{method_key}':\")\n",
    "        print(df_tiers_data.fillna(0))\n",
    "\n",
    "    if f'tiers_meth2' in grid_gdf.columns and app_config.COL_TIERS_FALCHETTA_MAJ in grid_gdf.columns:\n",
    "        grid_gdf['tiers_DHS_adjusted'] = grid_gdf['tiers_meth2'].where(grid_gdf['tiers_meth2'] != 5, 4) \n",
    "        grid_gdf['Similarity_Falchetta_DHS'] = grid_gdf['tiers_DHS_adjusted'] == grid_gdf[app_config.COL_TIERS_FALCHETTA_MAJ]\n",
    "        grid_gdf['Difference_Falchetta_DHS'] = abs(pd.to_numeric(grid_gdf['tiers_DHS_adjusted']) - pd.to_numeric(grid_gdf[app_config.COL_TIERS_FALCHETTA_MAJ]))\n",
    "\n",
    "        print(\"\\nSimilarity Analysis (Falchetta vs DHS-Method2):\")\n",
    "        print(f\"Number of lines with similar tiers: {grid_gdf['Similarity_Falchetta_DHS'].sum()}\")\n",
    "        print(f\"Mean difference in tiers: {grid_gdf['Difference_Falchetta_DHS'].mean():.2f}\")\n",
    "        print(f\"Median difference in tiers: {grid_gdf['Difference_Falchetta_DHS'].median():.2f}\")\n",
    "    \n",
    "    print(\"Finished Falchetta comparison.\")\n",
    "    return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235c8653-4045-49f4-8659-3b7508ffd523",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = compare_access_to_falchetta(grid, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c394279-0b13-4495-86ab-9e2a9f6b7427",
   "metadata": {},
   "source": [
    "### Final grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbce876-c2a5-4b0f-b968-d4d0a133d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.columns)\n",
    "grid.to_csv(config.RESIDENTIAL_OUTPUT_DIR / 'data_res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae812c1-53df-43a8-a3b5-9733c5d7a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'rwi_group' in grid.columns:\n",
    "    grid = grid.drop('rwi_group', axis=1)\n",
    "if 'tiers_DHS' in grid.columns:\n",
    "    grid = grid.drop('tiers_DHS', axis=1)\n",
    "if 'bin_labels' in grid.columns:\n",
    "    grid = grid.drop('bin_labels', axis=1)\n",
    "grid.to_file(config.RESIDENTIAL_OUTPUT_DIR / 'res_energy_map.shp', index=False)\n",
    "grid.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e4c941-51f3-4d8c-80f4-deb99b4e5c7e",
   "metadata": {},
   "source": [
    "### Map residential results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f5b1d-cfb0-467f-8d0d-9e92949c6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultRes = 'ResElec_kWh_meth2_scaled'\n",
    "grid[resultRes] = grid[resultRes]/10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57bff22-9f0a-4606-90e5-07fafee038cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the demand map with a log scale value\n",
    "# Create the axis first\n",
    "# sns.set_theme('poster')\n",
    "# sns.set_style('white')\n",
    "fig, ax = plt.subplots(figsize=(25, 15))\n",
    "\n",
    "# Add latitude and longitude labels\n",
    "ax.set_xlabel('Longitude (°)')\n",
    "ax.set_ylabel('Latitude (°)')\n",
    "\n",
    "# Plot data\n",
    "grid.sort_values(resultRes, ascending=True).plot(\n",
    "    ax=ax, column=resultRes, cmap=\"Reds\", legend=True, alpha=0.9, norm=colors.LogNorm(vmin = 1e-6, vmax=grid[resultRes].max()),\n",
    "    legend_kwds={\"label\": \"Consumption in kWh\"}) #, \"orientation\": \"horizontal\"})\n",
    "\n",
    "# admin_gdf.plot(ax=ax, edgecolor='brown', color='None', alpha=0.6)\n",
    "# region_gdf.plot(ax=ax, edgecolor='brown', color='None', alpha=0.2)\n",
    "# transmission lines\n",
    "# lines_gdf.plot(ax=ax, edgecolor='purple', color='purple', alpha=0.4)\n",
    "# MV_lines_gdf.plot(ax=ax, edgecolor='purple', color='purple', alpha=0.05)\n",
    "\n",
    "ax.set_aspect('equal', 'box')\n",
    "# txt = ax.set_title('Electricity consumption in the residential sector in {} (kWh)'.format(area) )\n",
    "# txt = ax.set_title('Electricity consumption in the residential sector (kWh)' )\n",
    "\n",
    "# print(grid.crs)\n",
    "\n",
    "# Compute the distance-per-pixel of the map\n",
    "# see https://geopandas.org/en/latest/gallery/matplotlib_scalebar.html#Geographic-coordinate-system-(degrees)\n",
    "# assert grid.crs == 'EPSG:4326'\n",
    "from shapely.geometry.point import Point\n",
    "points = gpd.GeoSeries(\n",
    "    [Point(-73.5, 40.5), Point(-74.5, 40.5)], crs=4326\n",
    ")  # Geographic WGS 84 - degrees\n",
    "points = points.to_crs(32619)  # Projected WGS 84 - meters\n",
    "distance_meters = points[0].distance(points[1])\n",
    "\n",
    "# Add a scale bar\n",
    "scalebar = ScaleBar(\n",
    "    distance_meters,\n",
    "    dimension=\"si-length\",\n",
    "    location='lower left',\n",
    "    length_fraction=0.1,\n",
    "    width_fraction=0.001,\n",
    "    units='m',\n",
    "    color='black',\n",
    "    fixed_value=None\n",
    ")\n",
    "\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "# Save plot as figure \n",
    "plt.savefig(config.RESIDENTIAL_OUTPUT_DIR / 'map_res_log.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516fbfc-8880-411b-b560-0547c535ee3b",
   "metadata": {},
   "source": [
    "# Services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d9795-e694-4a10-948e-89f7cf3a7bb8",
   "metadata": {},
   "source": [
    "## Electricity consumption based on number of buildings with access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0c621-2af1-4824-b499-3c8ba356103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_service_buildings_elec(grid_gdf, app_config, total_services_elec_gwh):\n",
    "    \"\"\"\n",
    "    Calculates services electricity demand based on the number of accessible service buildings.\n",
    "\n",
    "    It estimates the number of service buildings, then those with access, and\n",
    "    distributes the total national services electricity amongst them.\n",
    "\n",
    "    Args:\n",
    "        grid_gdf: GeoDataFrame of the hexagonal grid.\n",
    "        app_config: The configuration module.\n",
    "        total_services_elec_gwh: Total national services energy (GWh) from UN stats.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: grid_gdf with added column for building-based services energy.\n",
    "    \"\"\"\n",
    "    print(\"Calculating services electricity (building-based)...\")\n",
    "\n",
    "    if not all(col in grid_gdf.columns for col in [app_config.COL_BUILDINGS_SUM, app_config.COL_RES_BUI, app_config.PROB_ELEC_COL]):\n",
    "        raise KeyError(\"One or more required columns for service building electricity calculation are missing.\")\n",
    "\n",
    "    grid_gdf[app_config.COL_SER_BUI] = grid_gdf[app_config.COL_BUILDINGS_SUM] - grid_gdf[app_config.COL_RES_BUI]\n",
    "    grid_gdf[app_config.COL_SER_BUI_ACC] = grid_gdf[app_config.COL_SER_BUI] * grid_gdf[app_config.PROB_ELEC_COL]\n",
    "\n",
    "    total_ser_bui_with_access = grid_gdf[app_config.COL_SER_BUI_ACC].sum()\n",
    "    print(f\"Total services buildings with estimated access: {total_ser_bui_with_access:,.0f}\")\n",
    "\n",
    "    ser_elec_per_bui_kwh = (total_services_elec_gwh * 1e6) / total_ser_bui_with_access if total_ser_bui_with_access > 0 else 0\n",
    "    if total_ser_bui_with_access == 0: print(\"Warning: Total service buildings with access is 0.\")\n",
    "    \n",
    "    print(f\"Service electricity per accessible building: {ser_elec_per_bui_kwh:,.0f} kWh/building\")\n",
    "    grid_gdf[app_config.COL_SER_ELEC_KWH_BUI] = ser_elec_per_bui_kwh * grid_gdf[app_config.COL_SER_BUI_ACC]\n",
    "    \n",
    "    print(\"Finished calculating services electricity (building-based).\")\n",
    "    return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2bf0d0-0da3-403b-b8ac-b56f21ea1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = calculate_service_buildings_elec(grid, config, total_services_elec_GWh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ba822-35fb-4e51-8147-c5c090283ef2",
   "metadata": {},
   "source": [
    "## Energy consumption based on GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67793f63-702b-450e-bab3-6f9c94d1cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gdp_based_energy(grid_gdf, app_config, total_services_elec_gwh):\n",
    "    \"\"\"\n",
    "    Calculates services energy demand based on GDP data.\n",
    "\n",
    "    If GDP data is available, it\n",
    "    distributes total national services energy based on the GDP of each grid cell.\n",
    "    Otherwise, it sets the GDP-based energy column to zero.\n",
    "\n",
    "    Args:\n",
    "        grid_gdf: GeoDataFrame of the hexagonal grid.\n",
    "        app_config: The configuration module.\n",
    "        total_services_energy_gwh: Total national services energy (GWh) from UN stats.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: grid_gdf with added column for GDP-based services energy.\n",
    "    \"\"\"\n",
    "    print(\"Calculating services energy (GDP-based)...\")\n",
    "    \n",
    "    gdp_col = getattr(app_config, 'COL_GDP_PPP_MEAN', None) \n",
    "    col_ser_en_gdp = getattr(app_config, 'COL_SER_ELEC_KWH_GDP', 'Ser_elec_kWh_GDP') # Define target column name\n",
    "\n",
    "    if gdp_col and gdp_col in grid_gdf.columns:\n",
    "        total_gdp_kdollars = grid_gdf[gdp_col].sum() / 1000 \n",
    "        # print(f\"Total GDP: {total_gdp_kdollars:,.0f} k$\")\n",
    "        ser_elec_per_gdp_kwh_per_kdolar = (total_services_elec_gwh * 1e6) / total_gdp_kdollars if total_gdp_kdollars > 0 else 0\n",
    "        if total_gdp_kdollars == 0: print(\"Warning: Total GDP is 0.\")\n",
    "        \n",
    "        print(f\"Service energy per unit of GDP: {ser_elec_per_gdp_kwh_per_kdolar:,.2f} kWh/k$\")\n",
    "        grid_gdf[col_ser_en_gdp] = ser_elec_per_gdp_kwh_per_kdolar * (grid_gdf[gdp_col] / 1000)\n",
    "        print(f\"'{col_ser_en_gdp}' column created/updated.\")\n",
    "    else:\n",
    "        grid_gdf[col_ser_en_gdp] = 0.0 \n",
    "        print(f\"Warning: GDP column '{gdp_col}' not found or not defined. GDP-based service energy set to 0.\")\n",
    "        \n",
    "    print(\"Finished calculating services energy (GDP-based).\")\n",
    "    return grid_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27309c1e-60a6-47cc-a0ba-5d3561d96f15",
   "metadata": {},
   "source": [
    "## Energy consumption based on employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff0214-e26d-4f8b-adc6-9d5e63e7889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_employee_based_energy(grid_gdf, app_config, total_services_elec_gwh, df_censusdata):\n",
    "    \"\"\"\n",
    "    Calculates services energy demand based on the estimated number of employees.\n",
    "\n",
    "    This function uses DHS survey data for employment rates and working population shares,\n",
    "    combined with census data for population distribution, to estimate the number of\n",
    "    employees per grid cell. Total national services energy is then distributed\n",
    "    among employees with electricity access.\n",
    "\n",
    "    Args:\n",
    "        grid_gdf: GeoDataFrame of the hexagonal grid.\n",
    "        app_config: The configuration module.\n",
    "        total_services_elec_gwh: Total national services energy (GWh) from UN stats.\n",
    "        df_censusdata: DataFrame with provincial census data, indexed by region name.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: grid_gdf with added columns for employee counts and employee-based services energy.\n",
    "    \"\"\"\n",
    "    print(\"Calculating services energy (employee-based)...\")\n",
    "\n",
    "    # Use paths from config for DHS employee data\n",
    "    path_emp_women = app_config.DHS_EMPLOYEE_WOMEN_CSV\n",
    "    path_emp_men = app_config.DHS_EMPLOYEE_MEN_CSV\n",
    "    path_work_pop = app_config.DHS_WORKING_POP_SHARE_CSV\n",
    "\n",
    "    try:\n",
    "        data_employee_women = pd.read_csv(path_emp_women, index_col=(0, 1))\n",
    "        data_employee_men = pd.read_csv(path_emp_men, index_col=(0, 1))\n",
    "        data_workingpop_share = pd.read_csv(path_work_pop, index_col=(1, 0))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Employee data file not found: {e}. Skipping employee-based service energy calculation.\")\n",
    "        grid_gdf[app_config.COL_SER_ELEC_KWH_EMP] = 0.0\n",
    "        return grid_gdf\n",
    "\n",
    "    # Sum employee shares\n",
    "    data_employee_women['total_employee_share_women'] = data_employee_women[['professional/technical/managerial', 'clerical', 'sales', 'services', 'skilled manual']].sum(axis=1)\n",
    "    data_employee_men['total_employee_share_men'] = data_employee_men[['professional/technical/managerial', 'clerical', 'sales', 'services', 'skilled manual']].sum(axis=1)\n",
    "\n",
    "    # Ensure required columns exist in census data\n",
    "    required_census_cols = ['Share women', 'size_HH_urban', 'size_HH_rural']\n",
    "    if not all(col in df_censusdata.columns for col in required_census_cols):\n",
    "        raise KeyError(f\"Missing one or more required columns in census data: {required_census_cols}\")\n",
    "    \n",
    "    # --- FIX START: The calculation logic is moved into a more robust helper function ---\n",
    "\n",
    "    # Make a local copy to avoid SettingWithCopyWarning\n",
    "    df_censusdata_local = df_censusdata.copy()\n",
    "\n",
    "    # Define a single, more robust helper function for calculating population\n",
    "    def calculate_nb_gender(row, gender_type):\n",
    "        admin_name = row[app_config.COL_ADMIN_NAME]\n",
    "        loc_status = row[app_config.COL_LOC_ASSESSED]\n",
    "        hh_total = row[app_config.COL_HH_TOTAL]\n",
    "\n",
    "        # Get HH size for the specific location type (urban/rural)\n",
    "        hh_size = df_censusdata_local.loc[admin_name, f\"size_HH_{loc_status}\"]\n",
    "        \n",
    "        # Determine sex share and working pop share based on gender_type\n",
    "        if gender_type == 'women':\n",
    "            regional_sex_share = df_censusdata_local.loc[admin_name, 'Share women']\n",
    "            working_age_pop_share = data_workingpop_share.loc[('Female', loc_status), '15-49'] / 100\n",
    "        elif gender_type == 'men':\n",
    "            regional_sex_share = 1 - df_censusdata_local.loc[admin_name, 'Share women']\n",
    "            working_age_pop_share = data_workingpop_share.loc[('Male', loc_status), '15-49'] / 100\n",
    "        else:\n",
    "            raise ValueError('Unknown gender_type', gender_type)\n",
    "\n",
    "        return hh_total * hh_size * regional_sex_share * working_age_pop_share\n",
    "\n",
    "    # Apply the corrected function for both women and men\n",
    "    print(\"  Calculating number of men and women (15-49)...\")\n",
    "    grid_gdf['nb_women'] = grid_gdf.apply(calculate_nb_gender, args=('women',), axis=1)\n",
    "    grid_gdf['nb_men'] = grid_gdf.apply(calculate_nb_gender, args=('men',), axis=1)\n",
    "    \n",
    "    # --- FIX END ---\n",
    "\n",
    "    # Calculate working women/men (This part was mostly correct)\n",
    "    def calculate_working_gender(row, sex_col_name, employee_data_df, employee_share_col_name):\n",
    "        loc_status = row[app_config.COL_LOC_ASSESSED]\n",
    "        # Normalize the region name to match the index in the employee data\n",
    "        admin_name_processed = row[app_config.COL_ADMIN_NAME].lower().replace('-', ' ')\n",
    "        \n",
    "        try:\n",
    "            # Look up the working share from the pre-loaded employee data\n",
    "            percent_working = employee_data_df.loc[(admin_name_processed, loc_status), employee_share_col_name] / 100\n",
    "        except KeyError:\n",
    "            # If a specific region/location combo is missing, default to 0 to avoid errors\n",
    "            percent_working = 0\n",
    "        \n",
    "        return row[sex_col_name] * percent_working\n",
    "\n",
    "    print(\"  Calculating number of working men and women...\")\n",
    "    grid_gdf['nb_women_working'] = grid_gdf.apply(calculate_working_gender, args=('nb_women', data_employee_women, 'total_employee_share_women'), axis=1)\n",
    "    grid_gdf['nb_men_working'] = grid_gdf.apply(calculate_working_gender, args=('nb_men', data_employee_men, 'total_employee_share_men'), axis=1)\n",
    "    \n",
    "    # This redundant merge is no longer needed as the logic is handled inside the apply functions\n",
    "    # grid_gdf = grid_gdf.merge(df_censusdata['Share women'], on=app_config.COL_ADMIN_NAME, how='left')\n",
    "\n",
    "    # Sum up totals\n",
    "    grid_gdf[app_config.COL_TOTAL_EMPLOYEE] = grid_gdf['nb_women_working'] + grid_gdf['nb_men_working']\n",
    "    grid_gdf[app_config.COL_TOTAL_EMPLOYEE_WITH_ACCESS] = grid_gdf.loc[grid_gdf[app_config.COL_STATUS_ELECTRIFIED] == 'elec', app_config.COL_TOTAL_EMPLOYEE]\n",
    "    grid_gdf[app_config.COL_TOTAL_EMPLOYEE_WITH_ACCESS].fillna(0, inplace=True) # Ensure non-elec rows are 0, not NaN\n",
    "\n",
    "    total_employee_national_with_access = grid_gdf[app_config.COL_TOTAL_EMPLOYEE_WITH_ACCESS].sum()\n",
    "    print(f\"Total employees with access: {total_employee_national_with_access:,.0f}\")\n",
    "\n",
    "    if total_employee_national_with_access > 0:\n",
    "        ser_en_per_employee_kwh = (total_services_elec_gwh * 1e6) / total_employee_national_with_access # kWh / employee\n",
    "    else:\n",
    "        print(\"Warning: Total employees with access is 0. Energy per employee will be 0.\")\n",
    "        ser_en_per_employee_kwh = 0\n",
    "        \n",
    "    print(f\"Service electricity per accessible employee: {ser_en_per_employee_kwh:,.2f} kWh/employee\")\n",
    "    \n",
    "    # Distribute energy based on employees with access\n",
    "    grid_gdf[app_config.COL_SER_ELEC_KWH_EMP] = ser_en_per_employee_kwh * grid_gdf[app_config.COL_TOTAL_EMPLOYEE_WITH_ACCESS]\n",
    "    \n",
    "    print(\"Finished calculating services energy (employee-based).\")\n",
    "    return grid_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf7bc4b-837c-4415-8b73-411301eff2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = calculate_employee_based_energy(grid, config, total_services_elec_GWh, df_censusdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c349d70-2aa8-4680-a034-77b30bd3512c",
   "metadata": {},
   "source": [
    "## Weighted average of the three assessements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed216ce-6cd0-4c92-b002-4660f68a97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link between buildings and GDP\n",
    "plt.scatter(grid['serBUi_Acc'], grid['GDP_PPP'],s=1)\n",
    "\n",
    "# Add labels to the plot\n",
    "plt.xlabel('serBUi_Acc')\n",
    "plt.ylabel('GDP_PPP')\n",
    "\n",
    "# Set the axis to logarithmic scale\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3facc-2109-4200-82a5-4bf5522e9e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_access = 0.1 # lower value than residential because easier to connect services buildings\n",
    "alpha = 0\n",
    "beta = 0\n",
    "gama =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b25f215-8b9d-4207-ab62-fd477648121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute weighted average\n",
    "# Create a boolean Series indicating if probElec meets the condition\n",
    "# condition_met = grid[probElec] >= threshold_access\n",
    "# Assign the weighted average based on the condition\n",
    "grid['SElec_kWh_weighted'] = (beta * grid[config.COL_SER_ELEC_KWH_BUI] + gama * grid[config.COL_SER_ELEC_KWH_EMP] )\n",
    "\n",
    "totalSEn_kWh_weighted = grid['SElec_kWh_weighted'].sum()\n",
    "grid[config.COL_SER_ELEC_KWH_FINAL] = grid['SElec_kWh_weighted'] / totalSEn_kWh_weighted * total_services_elec_GWh *10**6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c754b-0db0-4431-95b3-d0c4e1eab6a6",
   "metadata": {},
   "source": [
    "## Results per region and map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6cbe75-cd4e-41df-bd89-9f10b4203a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "services_result = pd.DataFrame()\n",
    "services_result = grid.groupby('NAME_1')[config.COL_SER_ELEC_KWH_FINAL].sum() / 10**6 # conversion in GWh\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "services_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35c330-d61f-442b-aea3-6232ef67e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the energy consumption in services buildings map\n",
    "# Create the axis first\n",
    "fig, ax = plt.subplots(figsize=(25, 15))\n",
    "\n",
    "# Plot data\n",
    "grid.sort_values(config.COL_SER_ELEC_KWH_FINAL, ascending=True).plot(\n",
    "    ax=ax, column=config.COL_SER_ELEC_KWH_FINAL, cmap=\"Reds\", legend=True, alpha=0.9)\n",
    "\n",
    "ax.set_aspect('equal', 'box')\n",
    "# txt = ax.set_title('Services electricity consumption in {}'.format(area) )\n",
    "\n",
    "# Save plot as figure \n",
    "plt.savefig(out_path + '/services_map' +str(alpha) +str(gama)+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c826c-b532-4cdb-a608-e91eef2be83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.to_csv(config.RESIDENTIAL_OUTPUT_DIR / 'dataser.csv')\n",
    "grid.to_file(config.RESIDENTIAL_OUTPUT_DIR / 'ser_energy_map.shp', index=False)\n",
    "grid.to_file(config.RESIDENTIAL_OUTPUT_DIR / 'ser_energy_map.geojson', driver='GeoJSON', index=False)  \n",
    "grid.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0094b1-d09b-465c-8f88-95a6a927aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_servicesenergy_scaled = grid.groupby('NAME_1')[config.COL_SER_ELEC_KWH_FINAL].sum() \n",
    "print (\"Services electricity consumption assessed after scaling:\")\n",
    "for region in regions:\n",
    "    total_servicesenergy_scaled[region] = total_servicesenergy_scaled[region]/10**6  # conversion in GWh\n",
    "    print (region, f\"{total_servicesenergy_scaled[region]:,.1f}\", \"GWh\" )\n",
    "print (total_servicesenergy_scaled )\n",
    "print (total_servicesenergy_scaled.sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fbc82-cbfe-4a74-bd29-bb7a24588cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_servicesenergy_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af66c45-8d16-4c28-8000-a29b96bc8a48",
   "metadata": {},
   "source": [
    "# Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4b74c1-4f1e-49f1-a610-561a03fdf87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_Buienergy_scaled = total_servicesenergy_scaled + total_residentialenergy_scaled\n",
    "total_Buienergy_scaled = total_servicesenergy_scaled + result_afterscaling['meth2']\n",
    "print (\"Services electricity consumption assessed after scaling:\")\n",
    "for region in regions:\n",
    "    print (region, f\"{total_Buienergy_scaled[region]:,.1f}\", \"GWh\" )\n",
    "print (total_Buienergy_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c5587a-95af-4112-b7aa-fab371e36748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
